{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpjT888_osRZ",
        "outputId": "ec8e2b0d-0206-4a11-e7db-9eb067188668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNjE_D6ezRvX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for kaggle\n",
        "\n",
        "# dataset_path = \"/kaggle/input/cicids-17/merged_output.csv\"\n",
        "\n",
        "# data = pd.read_csv(dataset_path)\n",
        "\n",
        "# for local\n",
        "data=pd.read_csv('merged_output.csv', encoding='utf-8')\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "\n",
        "data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "\n",
        "y = data['Label']\n",
        "X = data.drop('Label', axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y = y_encoded\n",
        "\n",
        "\n",
        "constant_features = [col for col in X.columns if X[col].nunique() == 1]\n",
        "X.drop(columns=constant_features, inplace=True)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "X_scaled_non_neg = minmax_scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHanAqhZzTk1",
        "outputId": "db54c1eb-537b-49cb-8a19-bd3826174860"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Feature Set': 'ANOVA',\n",
              " 'Accuracy': 0.752251239613334,\n",
              " 'Precision': 0.7543459293464617,\n",
              " 'Recall': 0.752251239613334,\n",
              " 'F1-Score': 0.7462785968346386,\n",
              " 'ROC-AUC': 0.6068924445551545}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "anova_fs = SelectKBest(f_classif, k=20)\n",
        "anova_fs.fit(X_scaled, y)\n",
        "\n",
        "\n",
        "anova_selected_features = X.columns[anova_fs.get_support()]\n",
        "\n",
        "\n",
        "X_anova = X[anova_selected_features]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_anova, y, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000, solver='lbfgs')  \n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)  \n",
        "\n",
        "\n",
        "results_anova = {\n",
        "    \"Feature Set\": \"ANOVA\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred, average='weighted'),  # Adjusted for multiclass\n",
        "    \"Recall\": recall_score(y_test, y_pred, average='weighted'),  # Adjusted for multiclass\n",
        "    \"F1-Score\": f1_score(y_test, y_pred, average='weighted'),  # Adjusted for multiclass\n",
        "    \"ROC-AUC\": roc_auc_score(y_test, y_prob, multi_class='ovr') if y_prob is not None else None  # Adjusted for multiclass\n",
        "}\n",
        "\n",
        "results_anova\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-tqD2mR6LLA",
        "outputId": "6efd16d7-035a-478c-c330-2d881a46dd4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top K Features: Index(['Flow Duration', 'Bwd Packet Length Max', 'Bwd Packet Length Mean',\n",
            "       'Bwd Packet Length Std', 'Flow IAT Std', 'Flow IAT Max',\n",
            "       'Fwd IAT Total', 'Fwd IAT Std', 'Fwd IAT Max', 'Max Packet Length',\n",
            "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
            "       'FIN Flag Count', 'PSH Flag Count', 'Average Packet Size',\n",
            "       'Avg Bwd Segment Size', 'Idle Mean', 'Idle Max', 'Idle Min'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Get selected feature names from the ANOVA method\n",
        "anova_selected_features = X.columns[anova_fs.get_support()]\n",
        "\n",
        "# Print the top k features\n",
        "print(\"Top K Features:\", anova_selected_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af4pcoE8zX3N",
        "outputId": "a680d5de-9fbe-40a5-a16f-4172125e79c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Feature Set': 'Chi2',\n",
              " 'Accuracy': 0.7550238449716307,\n",
              " 'Precision': 0.7483319425455639,\n",
              " 'Recall': 0.7550238449716304,\n",
              " 'F1-Score': 0.7465944941264198,\n",
              " 'ROC-AUC': 0.6261088496695072}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Chi-Square - SelectKBest with chi2 (Requires non-negative data)\n",
        "chi2_fs = SelectKBest(chi2, k=20)\n",
        "chi2_fs.fit(X_scaled_non_neg, y)\n",
        "\n",
        "# Get selected features\n",
        "chi2_selected_features = X.columns[chi2_fs.get_support()]\n",
        "\n",
        "# Prepare dataset with selected features\n",
        "X_chi2 = X[chi2_selected_features]\n",
        "\n",
        "# Train and evaluate a model\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_chi2, y, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000, solver='lbfgs')  # Increase max_iter for convergence\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)  # Get full probability for multiclass\n",
        "\n",
        "# Metrics for multiclass classification\n",
        "results_chi2 = {\n",
        "    \"Feature Set\": \"Chi2\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred, average='weighted'),  # Adjusted for multiclass\n",
        "    \"Recall\": recall_score(y_test, y_pred, average='weighted'),  # Adjusted for multiclass\n",
        "    \"F1-Score\": f1_score(y_test, y_pred, average='weighted'),  # Adjusted for multiclass\n",
        "    \"ROC-AUC\": roc_auc_score(y_test, y_prob, multi_class='ovr') if y_prob is not None else None  # Adjusted for multiclass\n",
        "}\n",
        "\n",
        "results_chi2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGr4ftDx99yA",
        "outputId": "dc2e4568-9f95-4899-9e2f-dc6207e58a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top K Features: Index(['Flow Duration', 'Bwd Packet Length Max', 'Bwd Packet Length Mean',\n",
            "       'Bwd Packet Length Std', 'Flow IAT Std', 'Flow IAT Max',\n",
            "       'Fwd IAT Total', 'Fwd IAT Std', 'Fwd IAT Max', 'Max Packet Length',\n",
            "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
            "       'FIN Flag Count', 'PSH Flag Count', 'Average Packet Size',\n",
            "       'Avg Bwd Segment Size', 'Idle Mean', 'Idle Max', 'Idle Min'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Get selected feature names from the ANOVA method\n",
        "chi2_selected_features = X.columns[chi2_fs.get_support()]\n",
        "\n",
        "# Print the top k features\n",
        "print(\"Top K Features:\", chi2_selected_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-HbdSgAncad"
      },
      "source": [
        "**Random Forest Classifier (RF)** :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tIHmfhJzcFV",
        "outputId": "b92876a7-ccd0-45d0-fdf3-426c502275dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Feature Set': 'RandomForest', 'Accuracy': 0.8915856163850938, 'Precision': 0.8811032958406525, 'Recall': 0.8915856163850938, 'F1-Score': 0.8820158674890421, 'ROC-AUC': 0.9238974285342869}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already defined as your features and target variable\n",
        "\n",
        "# Standardize the features (if not already scaled)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # X should be a DataFrame or array\n",
        "\n",
        "# Convert X_scaled back to DataFrame with proper column names\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Train Random Forest for feature selection\n",
        "rf_fs = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_fs.fit(X_scaled, y)\n",
        "\n",
        "# Select top 20 most important features\n",
        "rf_selected_indices = np.argsort(rf_fs.feature_importances_)[-20:]  # Get column indices\n",
        "rf_selected_features = X.columns[rf_selected_indices]  # Get corresponding column names\n",
        "\n",
        "# Use only selected features\n",
        "X_rf = X_scaled_df[rf_selected_features]\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rf, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Get probabilities (for ROC-AUC)\n",
        "y_prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "# Handle ROC-AUC for multiclass\n",
        "roc_auc = None\n",
        "if y_prob is not None and len(y_prob.shape) > 1:\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "# Compute evaluation metrics\n",
        "results_rf = {\n",
        "    \"Feature Set\": \"RandomForest\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred, average='weighted', zero_division=1),\n",
        "    \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred, average='weighted'),\n",
        "    \"ROC-AUC\": roc_auc\n",
        "}\n",
        "\n",
        "print(results_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUGuj5nynnLg"
      },
      "source": [
        "**K features in RF** :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXC6sb22DTTK",
        "outputId": "94c485a8-8705-4c6d-c08e-1bba6b41715e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top K Features: Index(['Fwd Packet Length Mean', 'Bwd Packets/s', 'Bwd Header Length',\n",
            "       'Fwd Packet Length Max', 'Avg Fwd Segment Size', 'Packet Length Std',\n",
            "       'Init_Win_bytes_forward', 'Bwd Packet Length Max', 'Destination Port',\n",
            "       'Max Packet Length', 'Packet Length Mean', 'Subflow Fwd Bytes',\n",
            "       'Total Length of Fwd Packets', 'Subflow Bwd Bytes',\n",
            "       'Avg Bwd Segment Size', 'Average Packet Size', 'Bwd Packet Length Std',\n",
            "       'Total Length of Bwd Packets', 'Bwd Packet Length Mean',\n",
            "       'Packet Length Variance'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(\"Top K Features:\", rf_selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVB-hC_En3FF"
      },
      "source": [
        "**Mutual_Info_Classifier (MI)**:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW3mRt9Xzc5V",
        "outputId": "6e892bfd-8681-41ba-b586-bee4eb442f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Feature Set': 'Mutual Information', 'Accuracy': 0.9006824765968637, 'Precision': 0.8958142332140586, 'Recall': 0.9006824765968637, 'F1-Score': 0.891335520223245, 'ROC-AUC': 0.9442472389359708}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Standardize the dataset\n",
        "\n",
        "# Convert X_scaled back to DataFrame with original column names\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Mutual Information - SelectKBest with mutual_info_classif\n",
        "mi_fs = SelectKBest(mutual_info_classif, k=20)\n",
        "mi_fs.fit(X_scaled, y)  # Ensure X_scaled is available\n",
        "\n",
        "# Get selected features\n",
        "mi_selected_features = X.columns[mi_fs.get_support()]\n",
        "\n",
        "# Prepare dataset with selected features\n",
        "X_mi = X_scaled_df[mi_selected_features]  # Use scaled version\n",
        "\n",
        "# Train and evaluate the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_mi, y, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "# Handle ROC-AUC for multiclass\n",
        "roc_auc = None\n",
        "if y_prob is not None and len(y_prob.shape) > 1:\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "# Compute metrics\n",
        "results_mi = {\n",
        "    \"Feature Set\": \"Mutual Information\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred, average='weighted', zero_division=1),\n",
        "    \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred, average='weighted'),\n",
        "    \"ROC-AUC\": roc_auc\n",
        "}\n",
        "\n",
        "print(results_mi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9s-CHILoEQ1"
      },
      "source": [
        "**K features in Mi** :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd963i4wDUvv",
        "outputId": "11092c8d-41d2-4363-8472-916272362ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top K Features: Index(['Destination Port', 'Total Length of Fwd Packets',\n",
            "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
            "       'Fwd Packet Length Mean', 'Bwd Packet Length Max',\n",
            "       'Bwd Packet Length Mean', 'Flow Bytes/s', 'Flow IAT Max',\n",
            "       'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\n",
            "       'Packet Length Variance', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
            "       'Avg Bwd Segment Size', 'Subflow Fwd Bytes', 'Subflow Bwd Bytes',\n",
            "       'Init_Win_bytes_forward', 'Init_Win_bytes_backward'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Print the top k features\n",
        "print(\"Top K Features:\", mi_selected_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOLhdcP4qxpH"
      },
      "source": [
        "**Pearson Classifier** :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2gBxpE6oZgV",
        "outputId": "b1fd19a0-7d7c-4a0d-ccf6-65e0622f11e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Feature Set': 'Pearson Correlation', 'Accuracy': 0.9328268839507011, 'Precision': 0.9335864563984232, 'Recall': 0.9328268839507011, 'F1-Score': 0.9270408991999707, 'ROC-AUC': 0.9358028405059338}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Standardize the dataset\n",
        "\n",
        "# Convert X_scaled back to DataFrame with original column names\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Pearson Correlation - Select top 20 features\n",
        "correlations = X_scaled_df.corrwith(pd.Series(y)).abs()\n",
        "pearson_selected_features = correlations.nlargest(20).index\n",
        "\n",
        "# Prepare dataset with selected features\n",
        "X_pearson = X_scaled_df[pearson_selected_features]  # Use scaled version\n",
        "\n",
        "# Train and evaluate the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pearson, y, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "# Handle ROC-AUC for multiclass\n",
        "roc_auc = None\n",
        "if y_prob is not None and len(y_prob.shape) > 1:\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "# Compute metrics\n",
        "results_pearson = {\n",
        "    \"Feature Set\": \"Pearson Correlation\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred, average='weighted', zero_division=1),\n",
        "    \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred, average='weighted'),\n",
        "    \"ROC-AUC\": roc_auc\n",
        "}\n",
        "\n",
        "print(results_pearson)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zViNhGKZq7sA"
      },
      "source": [
        "**K features in pearson**:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aJfKLfdqF-J",
        "outputId": "dd8f6ccc-cdea-4fd3-a24d-aa071bd436f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top K Features: Index(['PSH Flag Count', 'Min Packet Length', 'Bwd Packet Length Min',\n",
            "       'Bwd Packet Length Std', 'Fwd IAT Std', 'Packet Length Variance',\n",
            "       'Bwd Packet Length Max', 'Bwd Packets/s', 'Idle Max',\n",
            "       'Init_Win_bytes_forward', 'Idle Mean', 'Idle Min', 'Fwd IAT Max',\n",
            "       'Bwd Packet Length Mean', 'Avg Bwd Segment Size', 'Flow IAT Max',\n",
            "       'Packet Length Std', 'URG Flag Count', 'Max Packet Length',\n",
            "       'Fwd Packet Length Min'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Print the top k features\n",
        "print(\"Top K Features:\", pearson_selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhGODVynqZ3m"
      },
      "source": [
        "**RFE CLASSIFIER** :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "03ZpiJWuzfqd",
        "outputId": "10b29962-0c4a-4bf8-aadd-38024045a810"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Standardize the dataset\n",
        "\n",
        "# Convert X_scaled back to DataFrame with original column names\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Recursive Feature Elimination (RFE) - Select top 20 features\n",
        "logreg = LogisticRegression(max_iter=100, solver='liblinear', random_state=42)\n",
        "rfe = RFE(estimator=logreg, n_features_to_select=20)\n",
        "rfe.fit(X_scaled, y)\n",
        "\n",
        "# Select the top features\n",
        "rfe_selected_features = X.columns[rfe.support_]\n",
        "\n",
        "# Prepare dataset with selected features\n",
        "X_rfe = X_scaled_df[rfe_selected_features]  # Use scaled version\n",
        "\n",
        "# Train and evaluate the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "# Handle ROC-AUC for multiclass\n",
        "roc_auc = None\n",
        "if y_prob is not None and len(y_prob.shape) > 1:\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "# Compute metrics\n",
        "results_rfe = {\n",
        "    \"Feature Set\": \"RFE\",\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred, average='weighted', zero_division=1),\n",
        "    \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred, average='weighted'),\n",
        "    \"ROC-AUC\": roc_auc\n",
        "}\n",
        "\n",
        "print(results_rfe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCV79ZlXzh0P",
        "outputId": "7b8f364c-d12b-42a1-ea11-36c174058170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Bwd Packet Length Max', 5), ('Bwd Packet Length Mean', 5), ('Max Packet Length', 5), ('Packet Length Std', 5), ('Packet Length Variance', 5), ('Avg Bwd Segment Size', 5), ('Bwd Packet Length Std', 4), ('Flow IAT Max', 4), ('Packet Length Mean', 4), ('Average Packet Size', 4), ('Fwd IAT Std', 3), ('Fwd IAT Max', 3), ('PSH Flag Count', 3), ('Idle Mean', 3), ('Idle Max', 3), ('Idle Min', 3), ('Init_Win_bytes_forward', 3), ('Flow Duration', 2), ('Flow IAT Std', 2), ('Fwd IAT Total', 2)]\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "arr = [\n",
        "    'Flow Duration', 'Bwd Packet Length Max', 'Bwd Packet Length Mean',\n",
        "    'Bwd Packet Length Std', 'Flow IAT Std', 'Flow IAT Max', 'Fwd IAT Total',\n",
        "    'Fwd IAT Std', 'Fwd IAT Max', 'Max Packet Length', 'Packet Length Mean',\n",
        "    'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
        "    'PSH Flag Count', 'Average Packet Size', 'Avg Bwd Segment Size',\n",
        "    'Idle Mean', 'Idle Max', 'Idle Min', 'Flow Duration',\n",
        "    'Bwd Packet Length Max', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
        "    'Flow IAT Std', 'Flow IAT Max', 'Fwd IAT Total', 'Fwd IAT Std',\n",
        "    'Fwd IAT Max', 'Max Packet Length', 'Packet Length Mean',\n",
        "    'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
        "    'PSH Flag Count', 'Average Packet Size', 'Avg Bwd Segment Size',\n",
        "    'Idle Mean', 'Idle Max', 'Idle Min', 'Fwd Packet Length Mean',\n",
        "    'Bwd Packets/s', 'Bwd Header Length', 'Fwd Packet Length Max',\n",
        "    'Avg Fwd Segment Size', 'Packet Length Std', 'Init_Win_bytes_forward',\n",
        "    'Bwd Packet Length Max', 'Destination Port', 'Max Packet Length',\n",
        "    'Packet Length Mean', 'Subflow Fwd Bytes', 'Total Length of Fwd Packets',\n",
        "    'Subflow Bwd Bytes', 'Avg Bwd Segment Size', 'Average Packet Size',\n",
        "    'Bwd Packet Length Std', 'Total Length of Bwd Packets',\n",
        "    'Bwd Packet Length Mean', 'Packet Length Variance', 'Destination Port',\n",
        "    'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
        "    'Fwd Packet Length Max', 'Fwd Packet Length Mean',\n",
        "    'Bwd Packet Length Max', 'Bwd Packet Length Mean', 'Flow Bytes/s',\n",
        "    'Flow IAT Max', 'Max Packet Length', 'Packet Length Mean',\n",
        "    'Packet Length Std', 'Packet Length Variance', 'Average Packet Size',\n",
        "    'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Subflow Fwd Bytes',\n",
        "    'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\n",
        "    'PSH Flag Count', 'Min Packet Length', 'Bwd Packet Length Min',\n",
        "    'Bwd Packet Length Std', 'Fwd IAT Std', 'Packet Length Variance',\n",
        "    'Bwd Packet Length Max', 'Bwd Packets/s', 'Idle Max',\n",
        "    'Init_Win_bytes_forward', 'Idle Mean', 'Idle Min', 'Fwd IAT Max',\n",
        "    'Bwd Packet Length Mean', 'Avg Bwd Segment Size', 'Flow IAT Max',\n",
        "    'Packet Length Std', 'URG Flag Count', 'Max Packet Length',\n",
        "    'Fwd Packet Length Min'\n",
        "]\n",
        "\n",
        "# Count occurrences of each unique item\n",
        "counter = Counter(arr)\n",
        "\n",
        "# Get the 20 most common items\n",
        "fs = counter.most_common(20)\n",
        "\n",
        "# Print results\n",
        "print(fs)\n",
        "print(len(fs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
